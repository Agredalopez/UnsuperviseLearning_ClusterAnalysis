---
title: "**Análisis de Conglomerados**"
author: "Msc. Dennier Agreda López" 
date: "`r format(Sys.time(), '%d %B, %Y')`"
header-includes:
   - \usepackage{setspace}
output:
  pdf_document:
    fig_caption: true
    fig_height: 4
    fig_width: 4
    toc: true
    toc_depth: 4
    latex_engine: xelatex
    extra_dependencies: ["amsmath", "blkarray","caption","floatrow","fontspec"]
fontsize: 12pt
font-family: 'Helvetica'
---
\spacing{1.5}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, eval = T, message = F, cache=F, comment = F, warning = F)
```

```{r library}
library(ggpubr)
library(factoextra)
```

# 1. Introducción

En el mundo de *Machine Learning* existen un sinnumero de opciones para abordar diferentes problemas de negocio, tanto por el lado de los métodos *supervised learning*, lo cuales tienes la característica de tener una variable objetivo a predecir, así como las tareas abordadas por las técnicas de *reinforcement learning* es un área del aprendizaje automático inspirada en la psicología conductista, cuya ocupación es determinar qué acciones debe escoger un agente con el fin de maximizar alguna noción de "recompensa" o premio acumulado. 

Por el otro extremo, tenemos a las técnicas que buscan solucionar situaciones de negocio en dónde no se tiene un *target* natural, está interesado en descubrir propiedades útiles de los datos disponibles, este tipo de aprendizaje se le conoce como *unsupervised learning*.

El aprendizaje no supervisado se refiere a un conjunto diverso de técnicas para responder preguntas como ¿Existe una forma informativa de visualizar los datos? ¿Podemos descubrir subgrupos entre las variables o entre las observaciones? En general, el aprendizaje no supervisado se puede abordar por el lado de reducción de dimensionalidad y en la generación de agrupaciones que sean similares entre sí dentro de cada grupo.

Este documento en particular busca abordar el último punto mencionado en el párrafo anterior, también conocido como "**Análisis de Conglomerados**", partiendo de conceptos importantes, relacionados a la semejanza, distancia, evaluación de las técnicas y diferentes tipologías dependiendo el problema a abordar.

```{r fig1, fig.cap="\\label{fig:fig1}**Resultado de un Agrupamiento de _K-medias_ con K=3**", fig_align = "center"}
set.seed(2)
x<-matrix (rnorm (75*2) , ncol =2)
x[1:25 ,1]<-x[1:25 ,1]+3
x[1:25 ,2]<-x[1:25 ,2]-4
x[51:75 ,1]<-x[51:75 ,1]
x[51:75 ,2]<-x[51:75 ,2]-4
km.out <-kmeans (x,3, nstart =20)
x<-data.frame(x)
x$cluster<-factor(km.out$cluster)
ggscatter(font.label = c(20, "serif"),
  x, x = "X1", y = "X2", ellipse = T,
  color = "cluster", palette = c("green","blue","red"),
  size = 1.5,  legend = "down", ggtheme = theme_bw(), 
  xlab = expression(italic("X"[1])),
  ylab = expression(italic("X"[2]))) + stat_mean(aes(color = cluster), size = 3)+
  theme(text=element_text(size=12,  family="serif")) 
#c("red","blue")[km.out$cluster]
```

# 2. Clustering

El análisis de conglomerados o clústeres, se le conoce también como segmentación de datos tiene una variedad de objetivos. Todos ellos relacionados con segmentar o agrupar un conjunto de objetos en subcolecciones o grupos.

Cuando agrupamos las observaciones de un conjunto de datos, buscamos dividirlas en grupos distintos para que las observaciones dentro de cada grupo sean bastante similares entre sí (homogeneidad), mientras que las observaciones en diferentes grupos sean bastante diferentes entre sí. Además, en ocasiones, el objetivo es organizar los segmentos en una jerarquía natural (agrupar o separar sucesivamente los clústeres).

En definitiva, para que esto sea concreto, debemos definir qué significa que dos o más observaciones sean *similares* o *diferentes*. De hecho, esta es a menudo una consideración específica del dominio que debe hacerse basándose en el conocimiento de los datos que se estudian. 

## 2.1. Aplicaciones

Entre los principales usos que se les da a las técnicas de de Agrupamiento se hallan:

* Segmentación de Cartera de Clientes
* Investigación de Mercados
* Marketing Dirigido
* Análisis de Redes Sociales
* Recomendaciones Personalizadas[^1]
* Seguros
* Procesamiento de Imágenes
* Árboles Genealógicos - Filogenéticos

**Nota:** El agrupamiento es una técnica exploratoria de datos, ***genera hipótesis***, no las valida, es decir a posteriori el analista tiene que encontrar justificación análitica a los resultados.

# 3. Indicadores y Métricas

Cuando se habla de agrupamiento se resaltan dos conceptos importantes que están asociados a la similitud entre datos que propocia la generación de grupos y la distancia entre cada grupo, es decir que tan heterogéneos son entre sí. Partiendo de ello, se considera dos puntos importantes que son la ***cohesión*** y la ***separación***.

## 3.1. Indicadores

El nivel de separabilidad y cohesión sirven de insumo para las métricas que se consideran en este documento y que serán estudiadas en los siguientes párrafos. No obstante en este punto se definirá los conceptos de distancias dentro de cada grupo y las distancias intergrupales.

* **Sum of Squared Within** ***(SSW)*****:** Suma de distancias al cuadrado de los miembros de un mismo grupo respecto al centroide. En esencia, evalúa la *cohesión* de los grupos generados. $$SSW=\sum_{i=1}^K \sum_{x{\in}C_{i}}(x-m_{i})^2 \label{eq1}\tag{Ec.∼1}$$

  *Donde:*

  - $K$     $=$ Número de grupos.
  - $m_{i}$ $=$ Centroide de iésimo grupo.
  - $x$     $=$ Un punto del grupo $C_{i}$.

* **Sum of Squared Between** ***(SSB)*****:** Suma de distancias a un punto medio del conjunto de datos La intención de este indicador es medir la *separación* entre los grupos. $$SSB=\sum_{i=1}^k n_{i}*(X-m_{i})^2 \label{eq2}\tag{Ec.∼2}$$

  *Donde:*

  - $K$     $=$ Número de grupos.
  - $n_{i}$ $=$ Número de elementos en el grupo $C_{i}$.
  - $m_{i}$ $=$ Centroide de iésimo grupo.
  - $X$     $=$ Punto medio del conjunto de datos.

## 3.2. Métricas

Dentro de las disyuntivas a las que se enfrenta el modelador, al intentar desarrollar un modelo de agrupamiento, es decidir el número de grupos deseados asociada a la estrategia de negocio o problema que busca abordar y qué tipo de criterios usar para la consideración de la cohesión y separación de los grupos encontrados. Estas especificaciones son abordadas en este apartado, vistos como las medidas de evaluación para determinar el número *ideal* de grupos para la colección de datos entrenada y qué consideraciones debe de tener para diseñar un propuesta razonable en términos de *semejanza* y/o *distancia*, dependiendo del tipo de datos iniciales a los que nos enfrentemos.

### 3.2.1. Evaluación

#### 3.2.1.1. Método del Codo

En el análisis de conglomerados, el método del codo es una heurística utilizada para determinar el número de conglomerados en un conjunto de datos. El método consiste en graficar la variación explicada como una función del número de grupos, y elegir el codo de la curva como el número de grupos para usar.

* Calcule el algoritmo de agrupación en clústeres (e.g., agrupamiento de $K-medias$) para diferentes valores de $k$. Por ejemplo, variando $k$ de 1 a 10 grupos.
* Para cada $k$, calcule la suma total del cuadrado de las distancia de cada grupo $(SSW)$.
* Trace la curva de $SSW$ de acuerdo con el número de grupos $k$.
* La ubicación de una curva (codo) en la parcela se considera generalmente como un indicador del número apropiado de agrupaciones.

```{r fig2, fig.cap="\\label{fig:fig2}**Método del Codo - K óptimo**", fig_align = "center"}
fviz_nbclust(x, kmeans, method = "wss")+labs(y = "SSW", x = "Number of clusters k",
         title = "number of clusters")
```

#### 3.2.1.2. Calinsky-Harabasz

#### 3.2.1.3. Davies-Bouldin

#### 3.2.1.4. Coeficiente de Silueta

### 3.2.2. Proximidad

#### 3.2.2.1 Tipos de Distancia

* *Euclidea:*
* *Manhattan:*
* *Chebychev:*
* *Minkowsky:*
* *Mahalanobis:*

#### 3.2.2.2. Tipos de Semejanza

* *Índice de Jaccard:*
* *Índice de Acoplamiento Simple:*
* *Índice de Russel:*
* *Índice de Dice:*
* *Semejanza Coseno:*

# 4. Tipología de Agrupamientos

## 4.1. Según la Jerarquía

## 4.2. Según la Cohesión

### 4.2.1. Basados en Centroides

### 4.2.2. Basados en Grafos

### 4.2.3. Basados en Densidades

## 4.3. Según la Pertenencia

### 4.3.1. Exclusivos

### 4.3.2. No Exclusivos

## 4.4. Según la Estructura

### 4.4.1. Aglomerativos

### 4.4.2. Divisivos

# 5. Caracterización de la Construcción

## 5.1. Secuencia Lógica

## 5.2. Matrices Importantes

### 5.2.1. Matriz de Características

### 5.2.2. Matriz de Proximidad

# 6. Agrupamiento Jerárquico

# 7. Agrupamiento Particional Global

# 8. Agrupamiento Particional Local

# 9. Agrupamiento Probabilístico

[^1]: Lo referente a Sistemas de Recomendación y las diversas técnicas aplicadas para estos fines no se serán abordados en este documento.